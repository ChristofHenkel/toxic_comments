{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/christof/miniconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/christof/miniconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n",
      "lowercase\n",
      "removing breaks\n",
      "expanding contractions\n",
      "replacing smileys\n",
      "replacing ip\n",
      "removing links\n",
      "replacing numbers\n",
      "removing bigrams\n",
      "isolating punct\n",
      "preprocessing\n",
      "lowercase\n",
      "removing breaks\n",
      "expanding contractions\n",
      "replacing smileys\n",
      "replacing ip\n",
      "removing links\n",
      "replacing numbers\n",
      "removing bigrams\n",
      "isolating punct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000001it [01:31, 21953.52it/s]\n",
      "100%|██████████| 377039/377039 [00:00<00:00, 1153811.38it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Input, Dense, Embedding, SpatialDropout1D, concatenate, PReLU\n",
    "from keras.layers import CuDNNGRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import Nadam, Adam\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import Callback, TensorBoard, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "import tensorflow as tf\n",
    "from global_variables import TRAIN_FILENAME, TEST_FILENAME, SAMPLE_SUBMISSION_FILENAME\n",
    "from preprocess_utils import preprocess\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "max_features = 150000\n",
    "maxlen = 200\n",
    "em = 'ft'\n",
    "embed_size = 0\n",
    "if em == 'glove':\n",
    "    embed_size = 200\n",
    "else:\n",
    "    embed_size = 300\n",
    "#fix4->fix5:去掉concatenate后的Dropout层，SpatialDropout1D百分比0.45->0.5\n",
    "#fix5->fix6:modelcheckpoint\n",
    "#fix6->fix7:preprocess, gru后+prelu和dropout etc.\n",
    "#fix7->fix8:LR decrese, glove twitter200d\n",
    "#fix8->fix9:10fold\n",
    "#fix9->fix11:dropout0.5->0.2, attention layer\n",
    "\n",
    "def glove_preprocess(text):\n",
    "    #adapted from https://nlp.stanford.edu/projects/glove/preprocess-twitter.rb\n",
    "    # Different regex parts for smiley faces\n",
    "    eyes = \"[8:=;]\"\n",
    "    nose = \"['`\\-]?\"\n",
    "    text = re.sub(\"https?:* \", \"<URL>\", text)\n",
    "    text = re.sub(\"www.* \", \"<URL>\", text)\n",
    "    text = re.sub(\"\\[\\[User(.*)\\|\", '<USER>', text)\n",
    "    text = re.sub(\"<3\", '<HEART>', text)\n",
    "    text = re.sub(\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<NUMBER>\", text)\n",
    "    text = re.sub(eyes + nose + \"[Dd)]\", '<SMILE>', text)\n",
    "    text = re.sub(\"[(d]\" + nose + eyes, '<SMILE>', text)\n",
    "    text = re.sub(eyes + nose + \"p\", '<LOLFACE>', text)\n",
    "    text = re.sub(eyes + nose + \"\\(\", '<SADFACE>', text)\n",
    "    text = re.sub(\"\\)\" + nose + eyes, '<SADFACE>', text)\n",
    "    text = re.sub(eyes + nose + \"[/|l*]\", '<NEUTRALFACE>', text)\n",
    "    text = re.sub(\"/\", \" / \", text)\n",
    "    text = re.sub(\"[-+]?[.\\d]*[\\d]+[:,.\\d]*\", \"<NUMBER>\", text)\n",
    "    text = re.sub(\"([!]){2,}\", \"! <REPEAT>\", text)\n",
    "    text = re.sub(\"([?]){2,}\", \"? <REPEAT>\", text)\n",
    "    text = re.sub(\"([.]){2,}\", \". <REPEAT>\", text)\n",
    "    pattern = re.compile(r\"(.)\\1{2,}\")\n",
    "    text = pattern.sub(r\"\\1\" + \" <ELONG>\", text)\n",
    "    return text\n",
    "\n",
    "def deduplicate(x, threshold):\n",
    "    word_list = x.split()\n",
    "    num_words = len(word_list)\n",
    "    if num_words == 0:\n",
    "        return x\n",
    "    else:\n",
    "        num_unique_words = len(set(word_list))\n",
    "        unique_ratio = num_words/num_unique_words\n",
    "        if unique_ratio > threshold:\n",
    "            x = ' '.join(x.split()[:num_unique_words])\n",
    "        return x\n",
    "\n",
    "train = pd.read_csv(TRAIN_FILENAME)\n",
    "test = pd.read_csv(TEST_FILENAME)\n",
    "submission = pd.read_csv(SAMPLE_SUBMISSION_FILENAME)\n",
    "\n",
    "if em == 'glove':\n",
    "    train['comment_text'] = train['comment_text'].apply(lambda x: glove_preprocess(x))\n",
    "    test['comment_text'] = test['comment_text'].apply(lambda x: glove_preprocess(x))\n",
    "\n",
    "train = preprocess(train)\n",
    "train = preprocess(train)\n",
    "\n",
    "X = train[\"comment_text\"].fillna(\" \").values\n",
    "Y = train[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]].values\n",
    "X_test = test[\"comment_text\"].fillna(\" \").values\n",
    "\n",
    "tokenizer_w = text.Tokenizer(num_words=max_features)\n",
    "tokenizer_w.fit_on_texts(texts=list(X) + list(X_test))\n",
    "\n",
    "X = tokenizer_w.texts_to_sequences(X)\n",
    "X_test = tokenizer_w.texts_to_sequences(X_test)\n",
    "\n",
    "X = sequence.pad_sequences(X, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "EMBEDDING_FILE = ''\n",
    "# EMBEDDING_FILE = '../embed/crawl-300d-2M.vec'\n",
    "if em == 'glove':\n",
    "    EMBEDDING_FILE = 'assets/embedding_models/glove/glove.twitter.27B.200d.txt'\n",
    "else:\n",
    "    EMBEDDING_FILE = 'assets/embedding_models/ft_300d_crawl/crawl-300d-2M.vec'\n",
    "embeddings_index = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in tqdm(open(EMBEDDING_FILE, encoding='UTF-8')))\n",
    "\n",
    "word_index = tokenizer_w.word_index \n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "for word, idx in tqdm(word_index.items()):\n",
    "    if idx >= max_features: \n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None: \n",
    "        embedding_matrix[idx] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Embedding, Dropout, Bidirectional, GRU, Flatten, SpatialDropout1D, MaxPool1D,Concatenate\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch + 1, score))\n",
    "\n",
    "\n",
    "def squash(x, axis=-1):\n",
    "    # s_squared_norm is really small\n",
    "    # s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
    "    # scale = K.sqrt(s_squared_norm)/ (0.5 + s_squared_norm)\n",
    "    # return scale * x\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale\n",
    "\n",
    "class AttentionWeightedAverage(Layer):\n",
    "    \"\"\"\n",
    "    Computes a weighted average of the different channels across timesteps.\n",
    "    Uses 1 parameter pr. channel to compute the attention value for a single timestep.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, return_attention=False, **kwargs):\n",
    "        self.init = initializers.get('uniform')\n",
    "        self.supports_masking = True\n",
    "        self.return_attention = return_attention\n",
    "        super(AttentionWeightedAverage, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.input_spec = [InputSpec(ndim=3)]\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight(shape=(input_shape[2], 1),\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 initializer=self.init)\n",
    "        self.trainable_weights = [self.W]\n",
    "        super(AttentionWeightedAverage, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        # computes a probability distribution over the timesteps\n",
    "        # uses 'max trick' for numerical stability\n",
    "        # reshape is done to avoid issue with Tensorflow\n",
    "        # and 1-dimensional weights\n",
    "        logits = K.dot(x, self.W)\n",
    "        x_shape = K.shape(x)\n",
    "        logits = K.reshape(logits, (x_shape[0], x_shape[1]))\n",
    "        ai = K.exp(logits - K.max(logits, axis=-1, keepdims=True))\n",
    "\n",
    "        # masked timesteps have zero weight\n",
    "        if mask is not None:\n",
    "            mask = K.cast(mask, K.floatx())\n",
    "            ai = ai * mask\n",
    "        att_weights = ai / (K.sum(ai, axis=1, keepdims=True) + K.epsilon())\n",
    "        weighted_input = x * K.expand_dims(att_weights)\n",
    "        result = K.sum(weighted_input, axis=1)\n",
    "        if self.return_attention:\n",
    "            return [result, att_weights]\n",
    "        return result\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return self.compute_output_shape(input_shape)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        output_len = input_shape[2]\n",
    "        if self.return_attention:\n",
    "            return [(input_shape[0], output_len), (input_shape[0], input_shape[1])]\n",
    "        return (input_shape[0], output_len)\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        if isinstance(input_mask, list):\n",
    "            return [None] * len(input_mask)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# A Capsule Implement with Pure Keras\n",
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "\n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule,\n",
    "                                            self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, MaxPooling1D, Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, add,BatchNormalization\n",
    "from keras.layers import Dense, Embedding, Input, Bidirectional, concatenate, PReLU, SpatialDropout1D, Activation\n",
    "from keras.optimizers import Adam, RMSprop, Nadam\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "act, pad, kernel_ini = \"linear\", \"same\", \"he_uniform\"\n",
    "def build_model(units = 0, k = 0, num_block = 0, lr = 0.0, dr = 0.0):\n",
    "    inp = Input(shape = (maxlen, ))\n",
    "    emb = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n",
    "                    input_length = maxlen, trainable = False)(inp)\n",
    "    emb = SpatialDropout1D(dr)(emb)\n",
    "    #capsule = Capsule(num_capsule=256, dim_capsule=8, routings=3)(emb)\n",
    "    capsule = Capsule(num_capsule=128, dim_capsule=32, routings=3)(emb)\n",
    "    capsule = Capsule(num_capsule=64, dim_capsule=32, routings=3)(capsule)\n",
    "    capsule = Capsule(num_capsule=32, dim_capsule=32, routings=3)(capsule)\n",
    "    capsule = Capsule(num_capsule=16, dim_capsule=32, routings=3)(capsule)\n",
    "    capsule = Capsule(num_capsule=8, dim_capsule=32, routings=3)(capsule)\n",
    "    \n",
    "    out_put = Flatten()(capsule)\n",
    "\n",
    "    out_put = Dense(6, activation = \"sigmoid\")(out_put)\n",
    "    model = Model(inputs = inp, outputs = out_put)\n",
    "    #model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr=lr), metrics = [\"accuracy\"])\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr=lr), metrics = [\"accuracy\"])\n",
    "    #lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout, MaxPooling1D, Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, add,BatchNormalization\n",
    "from keras.layers import Dense, Embedding, Input, Bidirectional, concatenate, PReLU, SpatialDropout1D, Activation\n",
    "from keras.optimizers import Adam, RMSprop, Nadam\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "act, pad, kernel_ini = \"linear\", \"same\", \"he_uniform\"\n",
    "def build_model(units = 0, k = 0, num_block = 0, lr = 0.0, dr = 0.0):\n",
    "    inp = Input(shape = (maxlen, ))\n",
    "    emb = Embedding(nb_words, embed_size, weights = [embedding_matrix], \n",
    "                    input_length = maxlen, trainable = False)(inp)\n",
    "    emb = SpatialDropout1D(dr)(emb)\n",
    "    capsule = Capsule(num_capsule=128, dim_capsule=16, routings=3)(emb)\n",
    "    capsule = Capsule(num_capsule=64, dim_capsule=16, routings=3)(capsule)\n",
    "    capsule = Capsule(num_capsule=32, dim_capsule=16, routings=3)(capsule)\n",
    "    capsule = Capsule(num_capsule=16, dim_capsule=16, routings=3)(capsule)\n",
    "    capsule = Capsule(num_capsule=8, dim_capsule=16, routings=3)(capsule)\n",
    "    \n",
    "    out_put = Flatten()(capsule)\n",
    "\n",
    "    out_put = Dense(6, activation = \"sigmoid\")(out_put)\n",
    "    model = Model(inputs = inp, outputs = out_put)\n",
    "    #model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr=lr), metrics = [\"accuracy\"])\n",
    "    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr=lr), metrics = [\"accuracy\"])\n",
    "    #lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_35 (InputLayer)        (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "embedding_35 (Embedding)     (None, 200, 300)          45000000  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_35 (Spatia (None, 200, 300)          0         \n",
      "_________________________________________________________________\n",
      "capsule_135 (Capsule)        (None, 128, 32)           1228800   \n",
      "_________________________________________________________________\n",
      "capsule_136 (Capsule)        (None, 64, 32)            65536     \n",
      "_________________________________________________________________\n",
      "capsule_137 (Capsule)        (None, 32, 32)            32768     \n",
      "_________________________________________________________________\n",
      "capsule_138 (Capsule)        (None, 16, 32)            16384     \n",
      "_________________________________________________________________\n",
      "capsule_139 (Capsule)        (None, 8, 32)             8192      \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 46,353,222\n",
      "Trainable params: 1,353,222\n",
      "Non-trainable params: 45,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_model(units = 256, k = 3, num_block = 2, lr = 0.001, dr = 0.2)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143614 samples, validate on 15957 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[32,128,200,32]\n\t [[Node: training_22/Adam/gradients/capsule_145/MatMul_grad/MatMul_1 = BatchMatMul[T=DT_FLOAT, _class=[\"loc:@capsule_145/MatMul\"], adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](capsule_145/Reshape_3, training_22/Adam/gradients/capsule_145/Squeeze_grad/Reshape)]]\n\nCaused by op 'training_22/Adam/gradients/capsule_145/MatMul_grad/MatMul_1', defined at:\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-ea2343eba21b>\", line 21, in <module>\n    verbose = 1, callbacks = [ra_val, early_stop, check_point])\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1646, in fit\n    self._make_train_function()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 434, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2512, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 1027, in _BatchMatMul\n    grad_y = math_ops.matmul(x, grad, adjoint_a=False, adjoint_b=False)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1861, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 709, in _batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'capsule_145/MatMul', defined at:\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 21 identical lines from previous traceback]\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-ea2343eba21b>\", line 15, in <module>\n    model = build_model(units = 256, k = 3, num_block = 3, lr = 0.001, dr = 0.2)\n  File \"<ipython-input-40-3e92db08e00e>\", line 13, in build_model\n    capsule = Capsule(num_capsule=128, dim_capsule=32, routings=3)(emb)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"<ipython-input-2-f1c5d115e543>\", line 137, in call\n    outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1151, in batch_dot\n    out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1861, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 709, in _batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,128,200,32]\n\t [[Node: training_22/Adam/gradients/capsule_145/MatMul_grad/MatMul_1 = BatchMatMul[T=DT_FLOAT, _class=[\"loc:@capsule_145/MatMul\"], adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](capsule_145/Reshape_3, training_22/Adam/gradients/capsule_145/Squeeze_grad/Reshape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,128,200,32]\n\t [[Node: training_22/Adam/gradients/capsule_145/MatMul_grad/MatMul_1 = BatchMatMul[T=DT_FLOAT, _class=[\"loc:@capsule_145/MatMul\"], adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](capsule_145/Reshape_3, training_22/Adam/gradients/capsule_145/Squeeze_grad/Reshape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-ea2343eba21b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcheck_point\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"min\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     history = model.fit(X_train, Y_train, batch_size = 32, epochs = 10, validation_data = (X_valid, Y_valid), \n\u001b[0;32m---> 21\u001b[0;31m                     verbose = 1, callbacks = [ra_val, early_stop, check_point])\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[32,128,200,32]\n\t [[Node: training_22/Adam/gradients/capsule_145/MatMul_grad/MatMul_1 = BatchMatMul[T=DT_FLOAT, _class=[\"loc:@capsule_145/MatMul\"], adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](capsule_145/Reshape_3, training_22/Adam/gradients/capsule_145/Squeeze_grad/Reshape)]]\n\nCaused by op 'training_22/Adam/gradients/capsule_145/MatMul_grad/MatMul_1', defined at:\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/base_events.py\", line 1426, in _run_once\n    handle._run()\n  File \"/home/christof/miniconda3/lib/python3.6/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 102, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-ea2343eba21b>\", line 21, in <module>\n    verbose = 1, callbacks = [ra_val, early_stop, check_point])\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 1646, in fit\n    self._make_train_function()\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/training.py\", line 970, in _make_train_function\n    loss=self.total_loss)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 91, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 434, in get_updates\n    grads = self.get_gradients(loss, params)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/optimizers.py\", line 78, in get_gradients\n    grads = K.gradients(loss, params)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 2512, in gradients\n    return tf.gradients(loss, variables, colocate_gradients_with_ops=True)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in gradients\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 353, in _MaybeCompile\n    return grad_fn()  # Exit early\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 581, in <lambda>\n    grad_scope, op, func_call, lambda: grad_fn(op, *out_grads))\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\", line 1027, in _BatchMatMul\n    grad_y = math_ops.matmul(x, grad, adjoint_a=False, adjoint_b=False)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1861, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 709, in _batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\n...which was originally created as op 'capsule_145/MatMul', defined at:\n  File \"/home/christof/miniconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n[elided 21 identical lines from previous traceback]\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-43-ea2343eba21b>\", line 15, in <module>\n    model = build_model(units = 256, k = 3, num_block = 3, lr = 0.001, dr = 0.2)\n  File \"<ipython-input-40-3e92db08e00e>\", line 13, in build_model\n    capsule = Capsule(num_capsule=128, dim_capsule=32, routings=3)(emb)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"<ipython-input-2-f1c5d115e543>\", line 137, in call\n    outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1151, in batch_dot\n    out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1861, in matmul\n    a, b, adj_x=adjoint_a, adj_y=adjoint_b, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 709, in _batch_mat_mul\n    \"BatchMatMul\", x=x, y=y, adj_x=adj_x, adj_y=adj_y, name=name)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/christof/miniconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,128,200,32]\n\t [[Node: training_22/Adam/gradients/capsule_145/MatMul_grad/MatMul_1 = BatchMatMul[T=DT_FLOAT, _class=[\"loc:@capsule_145/MatMul\"], adj_x=false, adj_y=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](capsule_145/Reshape_3, training_22/Adam/gradients/capsule_145/Squeeze_grad/Reshape)]]\n"
     ]
    }
   ],
   "source": [
    "fold_count = 10\n",
    "fold_size = len(X) // 10\n",
    "for fold_id in range(0, fold_count):\n",
    "    fold_start = fold_size * fold_id\n",
    "    fold_end = fold_start + fold_size\n",
    "\n",
    "    if fold_id == fold_size - 1:\n",
    "        fold_end = len(X)\n",
    "\n",
    "    X_valid = X[fold_start:fold_end]\n",
    "    Y_valid = Y[fold_start:fold_end]\n",
    "    X_train = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "    Y_train = np.concatenate([Y[:fold_start], Y[fold_end:]])\n",
    "\n",
    "    model = build_model(units = 256, k = 3, num_block = 3, lr = 0.001, dr = 0.2)\n",
    "    file_path = \"DPCNN_CAPS_%s_.hdf5\" %fold_id\n",
    "    early_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 3)\n",
    "    ra_val = RocAucEvaluation(validation_data = (X_valid, Y_valid), interval = 1)\n",
    "    check_point = ModelCheckpoint(file_path, monitor = \"val_loss\", mode = \"min\", save_best_only = True, verbose = 1)\n",
    "    history = model.fit(X_train, Y_train, batch_size = 64, epochs = 10, validation_data = (X_valid, Y_valid), \n",
    "                    verbose = 1, callbacks = [ra_val, early_stop, check_point])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 8s 54us/step\n",
      "15957/15957 [==============================] - 1s 42us/step\n",
      "153164/153164 [==============================] - 8s 54us/step\n",
      "15957/15957 [==============================] - 1s 41us/step\n",
      "153164/153164 [==============================] - 9s 56us/step\n",
      "15957/15957 [==============================] - 1s 46us/step\n",
      "153164/153164 [==============================] - 9s 56us/step\n",
      "15957/15957 [==============================] - 1s 45us/step\n",
      "153164/153164 [==============================] - 9s 56us/step\n",
      "15957/15957 [==============================] - 1s 43us/step\n",
      "153164/153164 [==============================] - 9s 58us/step\n",
      "15957/15957 [==============================] - 1s 44us/step\n",
      "153164/153164 [==============================] - 9s 60us/step\n",
      "15957/15957 [==============================] - 1s 45us/step\n",
      "153164/153164 [==============================] - 9s 60us/step\n",
      "15957/15957 [==============================] - 1s 46us/step\n",
      "153164/153164 [==============================] - 10s 62us/step\n",
      "15957/15957 [==============================] - 1s 48us/step\n",
      "153164/153164 [==============================] - 10s 64us/step\n",
      "15958/15958 [==============================] - 1s 51us/step\n"
     ]
    }
   ],
   "source": [
    "from global_variables import LIST_CLASSES\n",
    "list_of_preds = []\n",
    "list_of_vals = []\n",
    "list_of_y = []\n",
    "fold_count = 10\n",
    "fold_size = len(X) // 10\n",
    "for fold_id in range(0, fold_count):\n",
    "    fold_start = fold_size * fold_id\n",
    "    fold_end = fold_start + fold_size\n",
    "\n",
    "    if fold_id == 9:\n",
    "        fold_end = len(X)\n",
    "\n",
    "    X_valid = X[fold_start:fold_end]\n",
    "    Y_valid = Y[fold_start:fold_end]\n",
    "    X_train = np.concatenate([X[:fold_start], X[fold_end:]])\n",
    "    Y_train = np.concatenate([Y[:fold_start], Y[fold_end:]])\n",
    "\n",
    "    file_path = 'DPCNN_3216_' + str(fold_id) + '_.hdf5'\n",
    "    #model = build_model(lr = 0.001)\n",
    "    #model.load_weights(file_path)\n",
    "    model = load_model(file_path)\n",
    "    preds = model.predict(X_test, batch_size = 256, verbose = 1)\n",
    "    list_of_preds.append(preds)\n",
    "    vals = model.predict(X_valid, batch_size = 256, verbose = 1)\n",
    "    list_of_vals.append(vals)\n",
    "    list_of_y.append(Y_valid)\n",
    "test_predicts = np.zeros(list_of_preds[0].shape)\n",
    "for fold_predict in list_of_preds:\n",
    "    test_predicts += fold_predict\n",
    "\n",
    "test_predicts /= len(list_of_preds)\n",
    "submission = pd.read_csv('assets/raw_data/sample_submission.csv')\n",
    "submission[LIST_CLASSES] = test_predicts\n",
    "submission.to_csv('DPCNN_3216_l2_test_data.csv', index=False)\n",
    "\n",
    "l2_data = pd.DataFrame(columns=['logits_' + c for c in LIST_CLASSES]+LIST_CLASSES)\n",
    "l2_data[['logits_' + c for c in LIST_CLASSES]] = pd.DataFrame(np.concatenate(list_of_vals,axis = 0))\n",
    "l2_data[LIST_CLASSES] = pd.DataFrame(np.concatenate(list_of_y,axis = 0))\n",
    "l2_data.to_csv('DPCNN_3216_l2_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
